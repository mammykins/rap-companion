# Dependency and reproducibility {#dep}

_This section is in development. Please [contribute to the discussion](https://github.com/ukgovdatascience/rap_companion/issues/89)._

## The trouble with dependencies

This section is about the code in your project that was written by other people, like R or Python packages. Management of these dependencies goes hand-in-hand with reproducibility. You can't recreate your outputs or update them if there are problems with your dependencies.

### Scheduled releases

Most statistical publications are updated on a scheduled basis when new data become available. You can see this on the [statistics release calendar on GOV.UK](https://www.gov.uk/government/statistics/announcements) and it's enshrined in [the Statistics Code of Practice](https://www.statisticsauthority.gov.uk/code-of-practice/the-code/trustworthiness/t3-orderly-release/).

Let's say you've used a RAP approach for your publication so that minimal effort is required to reproduce your outputs with the latest data. When the day comes to re-run your code to produce the latest update, you get a cryptic error. Hang on, this worked three months ago. What has gone wrong?

### Dependency hell

Using other people's code in your code can take a lot of weight off your shoulders: these _dependencies_ prevent you from having to implement tricky code problems yourself and limit the need for you update and fix problems. For example, you've probably imported packages to prevent you writing something from scratch, like the implementation of a statistical test. 

This is a powerful and useful concept, but the maintainers of the code _can change it at any time_. This means the software you used to produce your last release may have been updated and no longer works as you expect. Oh, and it's likely that your dependencies have dependencies of their own. You can get in a tangled mess quite easily.

Changes may be minimal and might not impact your publication. But a newer version may not behave in the way you expect. At best, your code won't run and you'll get a helpful error message. At worst, your code will execute but an impercetible but impactful error may have been introduced. Maybe a rounding function now rounds to the nearest 10 instead of the nearest 1000.

The bottom line: your publication is dependent on particular software _and_ its state at a given time. How can you deal with this?

## Strategies

There's a number of ways to protect yourself from dependency hell. Some are simpler and less automated, others are more complex and resolve the problem by improving reproducibility in general. 

RAP is language and tool-agnostic and so this section provides some ideas that you might consider. Other options are available and you should consider what is best for you based on your infrastructure and the technical knowledge of your team and anyone who might work on the project in future.

### Minimise your dependencies

The convenience and ubiquity of freely-available software packages mean that it's unlikely that you'll have zero dependencies in your code. Rather, the goal should be to:

* minimise the number of dependencies (do you have three packages for string manipulation when one would do?)
* restrict yourself to stable packages (try to avoid experimental packages or ones that haven't been updated in a long time)
* bear in mind any replacement packages (you should have an alternative if your dependency is no longer maintained and develops bugs)

This is enshrined in [the tinyverse philosophy of dependency management](http://www.tinyverse.org/)  as:

>Lightweight is the right weight

and

>Every dependency you add to your project is an invitation to break your project

You have been warned!

### Version numbers

Maintainers signal updates by increasing the version number of their software. This could be a simple patch of an earlier version's bug (e.g. version 3.2.7 replaces 3.2.6), or perhaps a major _breaking_ change (e.g. version 3.2.6 is update to version 4.0.0).

There are many ways to record each of the packages used in our analysis and their version numbers.

For example, in R you could use the `sessionInfo()` package.[^sessionInfo] This prints details about the current state of the working environment, including the packages and version numbers. 

```{r, eval=FALSE}
sessionInfo()
```
```
## R version 3.5.1 (2018-07-02)
## Platform: x86_64-apple-darwin15.6.0 (64-bit)
## Running under: macOS High Sierra 10.13.6
## 
## Matrix products: default
## BLAS: /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libBLAS.dylib
## LAPACK: /Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRlapack.dylib
## 
## locale:
## [1] en_GB.UTF-8/en_GB.UTF-8/en_GB.UTF-8/C/en_GB.UTF-8/en_GB.UTF-8
## 
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
## [1] packrat_0.4.8-1
## 
## loaded via a namespace (and not attached):
##  [1] bookdown_0.7      Rcpp_1.0.0        later_0.7.5      
##  [4] digest_0.6.18     mime_0.6          R6_2.3.0         
##  [7] magrittr_1.5      evaluate_0.11     xaringan_0.8     
## [10] stringi_1.2.4     promises_1.0.1    rstudioapi_0.8   
## [13] rmarkdown_1.11    tools_3.5.1       servr_0.10       
## [16] stringr_1.3.1     httpuv_1.4.5      xfun_0.3         
## [19] yaml_2.2.0        rsconnect_0.8.10  compiler_3.5.1   
## [22] htmltools_0.3.6   knitr_1.21        highlight_0.4.7.2
```

You can achieve a similar thing for Python with `pip freeze` in a shell script.[^pip-pin] Again, this provides a list of the packages available in the current environment and their version numbers.

```{bash, eval=FALSE}
pip freeze
```
```
## alabaster==0.7.10
## anaconda-client==1.6.14
## anaconda-navigator==1.8.7
## anaconda-project==0.8.2
## appnope==0.1.0
## appscript==1.0.1
## argcomplete==1.9.4
## asn1crypto==0.24.0
## astroid==1.6.3
...
```

But simply saving this information[^save-session] in your project folder isn't good dependency control. It:

* would be tedious for analysts to read these reports and download each recorded package version one-by-one
* records _every_ package and its version _on your whole system_, not just the ones relevant to your project
* isn't a reproducible or automated process

### Environments for dependency management

Ideally we want to automate the process of recording packages and their version numbers and have them installed in an isolated environment that's specific to our project. Doing this makes the project more portable -- you could run it easily from another machine that's configured differently to your own -- and it would therefore be more reproducible.

#### Package managers in R

A popular choice for automated package management in R is [the `packrat` package](https://rstudio.github.io/packrat/). The Packrat developers have created [a walkthrough on their website](https://rstudio.github.io/packrat/walkthrough.html).

You need only run one line to activate 'Packrat mode' for your project. 

```{r, eval=FALSE}
packrat::init("~/projects/rap-project")
```
```
Adding these packages to packrat:
            _         
    packrat   0.2.0.128

Fetching sources for packrat (0.2.0.128) ... OK (GitHub)
Snapshot written to '/Users/matt/projects/rap-project/packrat/packrat.lock'
Installing packrat (0.2.0.128) ... OK (built source)
init complete!
Packrat mode on. Using library in directory:
- "~/projects/rap-project/packrat/lib" 
```

What happened here? Packrat:

* was initiated within our project folder only
* found a specific version of a package (`packrat` itself!) in use within the project
* downloaded the package it found to a _private package library_, a new folder isolated within the project for storing packages
* recorded a snapshot of the current state of the dependencies

With Packrat mode on, any newly-downloaded packages are saved _within_ your project in the private library. By default, regular snapshots are taken to record the state of dependencies. You can also force this with `packrat::snapshot()`. 

```{r, eval=FALSE}
packrat::snapshot()
```
```
Adding these packages to packrat:
             _       
    plyr       1.8.1 
    Rcpp       0.11.2
    reshape2   1.4   
    stringr    0.6.2 

Fetching sources for plyr (1.8.1) ... OK (CRAN current)
Fetching sources for Rcpp (0.11.2) ... OK (CRAN current)
Fetching sources for reshape2 (1.4) ... OK (CRAN current)
Fetching sources for stringr (0.6.2) ... OK (CRAN current)
Snapshot written to '/Users/matt/projects/rap-project/packrat/packrat.lock'
```

This shows a user-initiated snapshot after installing a few packages (`plyr`, `Rcpp`, `reshape2` and `stringr`). You can see that Packrat fetches the sources and records a snapshot.

So far this looks like an automated version of recording the output of 'sessionInfo()` with a special private library so you're only using specific package versions for your project. When you run this again in future, you'll have the exact versions you need to recreate the analysis. 

Great, but what if a collaborator downloads the package? This is where we see the power of the snapshot. When opening the project fresh on a new machine, Packrat automates the process of fetching the packages -- with their recorded version numbers -- and storing them in a private package library, created on the collaborator's machine.

```
Packrat is not installed in the local library -- attempting to bootstrap an installation...
> Installing packrat into project private library:
- '/Users/matt/projects/rap-project/packrat/lib/x86_64-apple-darwin13.1.0/3.2.0'
* installing *source* package ‘packrat’ ...
** R
** inst
** preparing package for lazy loading
** help
*** installing help indices
** building package indices
** testing if installed package can be loaded
* DONE (packrat)
> Attaching packrat
> Restoring library
Installing plyr (1.8.1) ... OK (built source)
Installing Rcpp (0.11.2) ... OK (built source)
Installing reshape2 (1.4) ... OK (built source)
Installing stringr (0.6.2) ... OK (built source)
> Packrat bootstrap successfully completed. Entering packrat mode...
Packrat mode on. Using library in directory:
- "~/projects/babynames/packrat/lib"
```

Note that [there are some caveats](https://rstudio.github.io/packrat/limitations.html) to using Packrat.

A similar tool to `packrat` is [the `checkpoint` package](https://github.com/RevolutionAnalytics/checkpoint/wiki) from Microsoft's Revolution Analytics. It works like `packrat` but you simply `checkpoint()` your project for a given _date_. This allows you to call the packages from that date into a private library for that project. It works by fetching the packages from the Microsoft R Application Network (MRAN), which is a daily snapshot of [CRAN](https://cran.r-project.org/). One caveat is that you're dependent on MRAN to continue snapshotting CRAN and for it to continue to be maintained.

#### Virtual environments in Python

In Python we can create an isolated environment for our project and load packages into it.

This is possible with tools like [`virtualenv` and `Pipenv`](https://docs.python-guide.org/dev/virtualenvs/).

We can set up a virtual environment in our project folder, activate it, install any packages we need and then record them in a file for use in future. A shell script to do this might be:

```{bash, eval=FALSE}
# 1. Navigate to your project folder
cd ~/projects/rap-project/

# 2. Create a virtual environment folder there
virtualenv venv  # 'venv' will be the folder name

# 3. 'Activate' the virtual environment
source venv/bin/activate
```

You can now tell you're in the virtual environment because your shell prompt starts with `(venv)`, which is what we named our virtual environment folder (by convention) in step 2. Let's continue.

```{bash, eval=FALSE}
# 4. Install the packages you need, e.g. numpy
pip install numpy

# 5. Record the package-version list to a file in your home directory
pip freeze > requirements.txt

# 6. Deactivate the virtual environment when you're done
deactivate
```

When another user downloads your version-controlled project folder, the requirements.txt file will be there. Now they can create a virtual environment on their machine following steps 1 to 3 above, but rather than `pip install packageName` for each package they need, they can automate the process by installing everything from the requirements.txt file. From the shell:

```{bash, eval=FALSE}
pip install -r requirements.txt
```

This will download the packages one by one into the virtual environment in their copy of the project virtual environment.

## Containers

### Theory

Storing information about third-party packages is great, but there are still dependency management and reproducibility issues. Collaborators could still encounter errors if they: 

* try to run your code in an later version of the language you used during development
* use a different or updated Integrated Development Environment (IDE, like RStudio or Jupyter Notebooks)
* try to re-run the analysis on a Linux machine but the original was developed on Windows, for example

Fortunately, there are options to deal with this. One is [Docker](https://www.docker.com/), which effectively allows you to create a virtual computer inside your computer -- a _container_ -- with everything you need to recreate the analysis under consistent conditions, regardless of who you are and what equipment you're using.

It works like this:

1. Create a 'dockerfile'. This is like a plain-text recipe that will build from scratch everything you need for your project to run. It's just a textfile that you can put under version control.
2. Run the dockerfile to generate a Docker 'image'. The image is an instance of the environment and everything you need to recreate your analysis. It's a delicious cake you made following the recipe.
3. Other people can follow the dockerfile recipe to make their own copies of the delicious image cake. Each running instance of an image is called a container.

You can learn more about this process by [following the curriculum on Docker's website](https://docker-curriculum.com/). You can also read about the use of Docker [in the Department for Work and Pensions](https://dwpdigital.blog.gov.uk/2018/05/18/using-containers-to-deliver-our-data-projects/) (DWP). Phil Chapman [wrote more about the technical side of this process](https://chapmandu2.github.io/post/2018/05/26/reproducible-data-science-environments-with-docker/).

### Making it easier

You don't have to build everything from scratch. [Docker hub](https://hub.docker.com/) is a big library of pre-prepared container images. For example, the [rocker project on Docker hub](https://hub.docker.com/u/rocker) lists a number of images containing R-specific tools like [rocker/tidyverse](https://hub.docker.com/r/rocker/tidyverse) that contains R, RStudio and [the tidyverse packages](https://tidyverse.tidyverse.org/). You can specify a rocker image in your dockerfile to make your life easier. Learn more about [rOpenSci labs tutorial](http://ropenscilabs.github.io/r-docker-tutorial/)

As well as rocker, R users can set up Docker from within an interactive R session: [the `containerit` package](https://o2r.info/containerit/index.html) lets you create a dockerfile given the current state of your session. This simplifies the process a great deal.

R users can also read [Docker for the useR](https://github.com/noamross/nyhackr-docker-talk) by Noam Ross and [an introduction to Docker for R users](https://colinfay.me/docker-r-reproducibility/) by Colin Fay.

[^sessionInfo]: There's also a `session_info()` function in each of the `devtools`, `xfun` and `sessioninfo` packages, which provide more detail on things like a package's source (e.g. CRAN or GitHub) and give the version number in a separate column.
[^pip-pin]: These should be 'pinned' meaning that they're in the form `packageName==1.3.2` rather than `packageName>=1.3.2`. We're interested in storing _specific versions_, not _specific versions or newer_.
[^save-session]: With something like `writeLines(capture.output(sessionInfo()), "sessionInfo.txt")` within R and `pip freeze > requirements.txt` in the shell for Python.