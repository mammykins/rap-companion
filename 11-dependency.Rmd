# Dependency management {#dep}

## The trouble with dependencies

### Scheduled releases

Most statistical publications are updated on a scheduled basis when new data become available. You can see this on the [statistics release calendar on GOV.UK](https://www.gov.uk/government/statistics/announcements).

Let's say you've used a RAP approach to adhere to the principles laid out in [the Code of Practice for Statistics](https://www.statisticsauthority.gov.uk/code-of-practice/): you're using [innovation and improvement](https://www.statisticsauthority.gov.uk/code-of-practice/the-code/value/v4-innovation-and-improvement/) to produce automated [orderly releases](https://www.statisticsauthority.gov.uk/code-of-practice/the-code/trustworthiness/t3-orderly-release/) with [sound methods](https://www.statisticsauthority.gov.uk/code-of-practice/the-code/quality/q2-sound-methods/) and [assured quality](https://www.statisticsauthority.gov.uk/code-of-practice/the-code/quality/q3-assured-quality/). 

Great. This means you have what you need to reproduce the publication when it's time for the next release. What could possibly go wrong?

### Dependency hell

A major problem is that you have _dependencies_ on other people's code. For example, you've probably imported packages or modules to perform analyses or create plots. This is powerful and useful, but the maintainers of that code can change it at any time. This means the software you used to produce your last release may have been updated.

A maintainer should update the version number of their package when something changes. This could be a simple patch of an earlier version's bug (e.g. version 3.2.7 replaces 3.2.6), through to a major _breaking_ change (e.g. version 3.2.6 is update to version 4.0.0).

This may not always be an issue. Changes may be minimal and might not impact your publication. But a newer version may not behave in the way you expect. 

At best, your code won't run and you'll get a helpful error message. At worst, your code will execute but an impercetible error may have introduced. Maybe a rounding function now rounds to the nearest 10 instead of the nearest 1000.

If you don't have a way to manage this problem then your workflow isn't truly reproducible. You could run the same code now and in a year's time and the output could be different.

The bottom line: your publication is dependent on particular software _and_ its state at a given time. How can you deal with this?

## Strategies

There's a number of ways to protect yourself from dependency issues. Some are simpler and less automated, others are more complex and resolve the problem by improving reproducibility in general. 

RAP is language and tool-agnostic and so this section provides some ideas that you might consider. Other options are available and you should consider what is best for you based on your infrastructure and the technical knowledge of you, your team and anyone who might work on the project in future.

### Version numbers

We can record each package and the version we used during the analysis.

For example, you could use `sessionInfo()` in R.[^sessionInfo]

```{r, eval=FALSE}
sessionInfo()
```
```
## R version 3.5.1 (2018-07-02)
## Platform: x86_64-apple-darwin15.6.0 (64-bit)
## Running under: macOS High Sierra 10.13.6
## 
## Matrix products: default
## BLAS: /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libBLAS.dylib
## LAPACK: /Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRlapack.dylib
## 
## locale:
## [1] en_GB.UTF-8/en_GB.UTF-8/en_GB.UTF-8/C/en_GB.UTF-8/en_GB.UTF-8
## 
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
## [1] packrat_0.4.8-1
## 
## loaded via a namespace (and not attached):
##  [1] bookdown_0.7      Rcpp_1.0.0        later_0.7.5      
##  [4] digest_0.6.18     mime_0.6          R6_2.3.0         
##  [7] magrittr_1.5      evaluate_0.11     xaringan_0.8     
## [10] stringi_1.2.4     promises_1.0.1    rstudioapi_0.8   
## [13] rmarkdown_1.11    tools_3.5.1       servr_0.10       
## [16] stringr_1.3.1     httpuv_1.4.5      xfun_0.3         
## [19] yaml_2.2.0        rsconnect_0.8.10  compiler_3.5.1   
## [22] htmltools_0.3.6   knitr_1.21        highlight_0.4.7.2
```

You can achieve a similar thing in Python with `pip freeze` in a shell script.[^pip-pin]

```{bash, eval=FALSE}
pip freeze
```
```
## alabaster==0.7.10
## anaconda-client==1.6.14
## anaconda-navigator==1.8.7
## anaconda-project==0.8.2
## appnope==0.1.0
## appscript==1.0.1
## argcomplete==1.9.4
## asn1crypto==0.24.0
## astroid==1.6.3
...
```

But simply saving this information[^save-session] isn't good dependency control. It:

* would be tedious for analysts to download each recorded package version one-by-one
* records _every_ package and its version _on your whole system_; not just the ones relevant to your project
* isn't a reproducible or automated process

### Environments for dependency management

Ideally we want to _automate_ the process of recording packages and their version numbers and have them installed in an _isolated environment_ that's specific to our project. Doing this makes the project more _portable_ -- you could run it easily from another machine that's configured differently to your own -- and therfore it would be more _reproducible_.

#### Package managers in R

A popular choice in R is [the `packrat` package](https://rstudio.github.io/packrat/).

In this example from [Packrat's walkthrough](https://rstudio.github.io/packrat/walkthrough.html) you can see that calling `packrat::init()` in your project's repository causes 'Packrat mode' to activate for that project.

```{r, eval=FALSE}
packrat::init("~/projects/rap-project")
```
```
Adding these packages to packrat:
            _         
    packrat   0.2.0.128

Fetching sources for packrat (0.2.0.128) ... OK (GitHub)
Snapshot written to '/Users/matt/projects/rap-project/packrat/packrat.lock'
Installing packrat (0.2.0.128) ... OK (built source)
init complete!
Packrat mode on. Using library in directory:
- "~/projects/rap-project/packrat/lib" 
```

What happened here? Packrat:

* found a specific version of package in use in the project (itself!)
* downloaded it to a _private package library_, a new folder within the project for storing packages isolated within that project
* recorded a snapshot (a bit like saving `sessionInfo()`)

With Packrat mode on, any newly-downloaded packages are saved _within_ your project in the private library. By default, regular snapshots are taken to record the state of dependencies. You can force this with `packrat::snapshot()`. [This example](https://rstudio.github.io/packrat/walkthrough.html) shows a user-initiated snapshot after installing a few packages (`plyr`, `Rcpp`, `reshape2` and `stringr`). You can see that Packrat fetcches the sources and records a snapshot.

```{r, eval=FALSE}
packrat::snapshot()
```
```
Adding these packages to packrat:
             _       
    plyr       1.8.1 
    Rcpp       0.11.2
    reshape2   1.4   
    stringr    0.6.2 

Fetching sources for plyr (1.8.1) ... OK (CRAN current)
Fetching sources for Rcpp (0.11.2) ... OK (CRAN current)
Fetching sources for reshape2 (1.4) ... OK (CRAN current)
Fetching sources for stringr (0.6.2) ... OK (CRAN current)
Snapshot written to '/Users/matt/projects/rap-project/packrat/packrat.lock'
```

So far this loooks like an automated version of recording the output of 'sessionInfo()` with a special private library so you're only using specific package versions for your project. When you run this again in future, you'll have the exact versions you need to recreate the analysis. 

Great, but what if a collaborator downloads the package? This is where we see the power of the snapshot. When opening the project fresh on a new machine, Packrat automates the process of fetching the packages -- with their recorded version numbers -- and storing them in a private package library. created on that collaborator's machine.

```
Packrat is not installed in the local library -- attempting to bootstrap an installation...
> Installing packrat into project private library:
- '/Users/matt/projects/rap-project/packrat/lib/x86_64-apple-darwin13.1.0/3.2.0'
* installing *source* package ‘packrat’ ...
** R
** inst
** preparing package for lazy loading
** help
*** installing help indices
** building package indices
** testing if installed package can be loaded
* DONE (packrat)
> Attaching packrat
> Restoring library
Installing plyr (1.8.1) ... OK (built source)
Installing Rcpp (0.11.2) ... OK (built source)
Installing reshape2 (1.4) ... OK (built source)
Installing stringr (0.6.2) ... OK (built source)
> Packrat bootstrap successfully completed. Entering packrat mode...
Packrat mode on. Using library in directory:
- "~/projects/babynames/packrat/lib"
```

Note that [there are some caveats](https://rstudio.github.io/packrat/limitations.html) to using Packrat.

A similar tool to `packrat` is [the `checkpoint` package](https://github.com/RevolutionAnalytics/checkpoint/wiki) from Microsoft's Revolution Analytics. It works like `packrat` but you simply `checkpoint()` your project for a given _date_. This allows you to call the packages from that date into a private library for that project. It works by fetching the packages from the Microsoft R Application Network (MRAN), which is a daily snapshot of [CRAN](https://cran.r-project.org/). One caveat is that you're dependent on MRAN to continue snapshotting CRAN and for it to continue to be maintained.

#### Virtual environments in Python

Setting up an isolated environment -- also called a virtual environment -- is also an option in Python with things like [`virtualenv` and `Pipenv`](https://docs.python-guide.org/dev/virtualenvs/).

We can set up a virtual environment in our project folder, install any modules we need and then record them in a file for people to use in future. A shell script to do this might be:

```{bash, eval=FALSE}
# 1. Navigate to your project folder
cd ~/projects/rap-project/

# 2. Create a virtual environment folder there
virtualenv venv

# 3. 'Activate' the virtual environment
source venv/bin/activate
```

You can now tell you're in the virtual environment because your shell prompt starts with `(venv)`, which is what we named our virtual environment folder (by convention) in step 2. Lt's continue.

```{bash, eval=FALSE}
# 4. Install the modules you need
pip install numpy

# 5. Record the package-version list to a file in your home directory
pip freeze > requirements.txt

# 6. Deactivate the virtual environment when you're done
deactivate
```

When another user downloads your version-controlled project folder, the requirements.txt file will be there. Now they can create a virtual environment on their machine following steps 1 to 3 above, but rather than `pip install <module>` they can install based on the instructions from the requirements.txt file:

```{bash, eval=FALSE}
pip install -r requirements.txt
```

This will download the modules one by one into the virtual environment.

## Another problem

What about the version of the analytical software you're using? You may have written the original code in R version 3.4.1 but your computer is currently running R version 3.5.1. This is a similar problem to the issue of packages and modules: the functioning of code is also dependent on changes to the scripting tool itself.

You can think bigger than an isolated environment for package installation. We need some kind of isolated environment for both the packages _and_ the tools. And why stop there? We could put our functions, tests and data in there too.

A 'container' for our publication is a good idea. We can isolate all the components of our RAP publication and make it even more reproducible and portable.

### Docker

One way of doing this is to use Docker.


General

* [GOV.UK on software dependencies](https://www.gov.uk/service-manual/technology/managing-software-dependencies)
* [Docker for beginners](https://docker-curriculum.com/) by Docker
* [Using containers to deliver our data projects](https://dwpdigital.blog.gov.uk/2018/05/18/using-containers-to-deliver-our-data-projects/), a DWP blog by Phil Chapman, and [a more in-depth personal blog](https://chapmandu2.github.io/post/2018/05/26/reproducible-data-science-environments-with-docker/) 

R-focused

* [An introduction to Docker for R users](https://colinfay.me/docker-r-reproducibility/) by Colin Fay
* [Docker for the useR](https://github.com/noamross/nyhackr-docker-talk) by Noam Ross
* [Production-ready R: Getting started with R and docker](https://www.youtube.com/watch?v=lfG8cTqRRNA) by Elizabeth Stark at UseR!2018 (YouTube)
* [Applications with R and Docker](https://www.youtube.com/watch?v=JOIKy_89c-o) by Scott Came at UseR!2018 (YouTube)
* [Rocker](https://hub.docker.com/u/rocker) on Docker Hub
* [containerit](https://o2r.info/containerit/) packagedown site
* [rOpenSci labs tutorial](http://ropenscilabs.github.io/r-docker-tutorial/)

Papers

* [An Introduction to Rocker: Docker Containers for R](https://journal.r-project.org/archive/2017/RJ-2017-065/RJ-2017-065.pdf) in the R Journal, by Carl Boettiger and Dirk Eddelbuettel
* [Reproducibility of computational workflows is automated using continuous analysis](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC6103790/) in Nature Biotechnology
Google Scholar search results


[^sessionInfo]: There's also a `session_info()` function in each of the `devtools`, `xfun` and `sessioninfo` packages, which provide more detail on things like a package's source (e.g. CRAN or GitHub) and give the version number in a separate column.
[^pip-pin]: These should be 'pinned' meaning that they're in the form `module==1.3.2` rather than `module>=1.3.2`. We're interested in storing _specific versions_, not _specific versions or newer_.
[^save-session]: With something like `writeLines(capture.output(sessionInfo()), "sessionInfo.txt")` within R and `pip freeze > requirements.txt` in the shell for Python.