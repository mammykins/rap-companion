# Dependency management {#dep}

## The trouble with dependencies

### Scheduled releases

Most statistical publications are updated on a scheduled basis when new data become available. You can see this on the [statistics release calendar on GOV.UK](https://www.gov.uk/government/statistics/announcements).

Let's say you've used a RAP approach to adhere to the principles laid out in [the Code of Practice for Statistics](https://www.statisticsauthority.gov.uk/code-of-practice/): you're using [innovation and improvement](https://www.statisticsauthority.gov.uk/code-of-practice/the-code/value/v4-innovation-and-improvement/) to produce automated [orderly releases](https://www.statisticsauthority.gov.uk/code-of-practice/the-code/trustworthiness/t3-orderly-release/) with [sound methods](https://www.statisticsauthority.gov.uk/code-of-practice/the-code/quality/q2-sound-methods/) and [assured quality](https://www.statisticsauthority.gov.uk/code-of-practice/the-code/quality/q3-assured-quality/). 

Great. This means you have what you need to reproduce the publication when it's time for the next release. What could possibly go wrong?

### Dependency hell

A major problem is that you have _dependencies_ on other people's code. For example, you've probably imported packages or modules to perform analyses or create plots. This is powerful and useful, but the maintainers of that code can change it at any time. This means the software you used to produce your last release may have been updated.

A maintainer should update the version number of their package when something changes. This could be a simple patch of an earlier version's bug (e.g. version 3.2.7 replaces 3.2.6), through to a major _breaking_ change (e.g. version 3.2.6 is update to version 4.0.0).

This may not always be an issue. Changes may be minimal and might not impact your publication. But a newer version may not behave in the way you expect. 

At best, your code won't run and you'll get a helpful error message. At worst, your code will execute but an impercetible error may have introduced. Maybe a rounding function now rounds to the nearest 10 instead of the nearest 1000.

If you don't have a way to manage this problem then your workflow isn't truly reproducible. You could run the same code now and in a year's time and the output could be different.

The bottom line: your publication is dependent on particular software _and_ its state at a given time. How can you deal with this?

## Strategies

There's a number of ways to protect yourself from dependency issues. Some are simpler and less automated, others are more complex and resolve the problem by improving reproducibility in general. 

RAP is language and tool-agnostic and so this section provides some ideas that you might consider. Other options are available and you should consider what is best for you based on your infrastructure and the technical knowledge of you, your team and anyone who might work on the project in future.

### Record version numbers

One simple way to do this would be to record the packages and their version numbers. Yes, you could literally inspect every package, but there are functions that allow you to do this automatically.

You could use `sessionInfo()` to do this in R.[^sessionInfo]

```{r, eval=FALSE}
sessionInfo()
```
```
## R version 3.5.1 (2018-07-02)
## Platform: x86_64-apple-darwin15.6.0 (64-bit)
## Running under: macOS High Sierra 10.13.6
## 
## Matrix products: default
## BLAS: /System/Library/Frameworks/Accelerate.framework/Versions/A/Frameworks/vecLib.framework/Versions/A/libBLAS.dylib
## LAPACK: /Library/Frameworks/R.framework/Versions/3.5/Resources/lib/libRlapack.dylib
## 
## locale:
## [1] en_GB.UTF-8/en_GB.UTF-8/en_GB.UTF-8/C/en_GB.UTF-8/en_GB.UTF-8
## 
## attached base packages:
## [1] stats     graphics  grDevices utils     datasets  methods   base     
## 
## other attached packages:
## [1] packrat_0.4.8-1
## 
## loaded via a namespace (and not attached):
##  [1] bookdown_0.7      Rcpp_1.0.0        later_0.7.5      
##  [4] digest_0.6.18     mime_0.6          R6_2.3.0         
##  [7] magrittr_1.5      evaluate_0.11     xaringan_0.8     
## [10] stringi_1.2.4     promises_1.0.1    rstudioapi_0.8   
## [13] rmarkdown_1.11    tools_3.5.1       servr_0.10       
## [16] stringr_1.3.1     httpuv_1.4.5      xfun_0.3         
## [19] yaml_2.2.0        rsconnect_0.8.10  compiler_3.5.1   
## [22] htmltools_0.3.6   knitr_1.21        highlight_0.4.7.2
```

For Python you can use `pip freeze` in a shell script to achieve a similar thing.[^pip-pin]

```{bash, eval=FALSE}
pip freeze
```
```
## alabaster==0.7.10
## anaconda-client==1.6.14
## anaconda-navigator==1.8.7
## anaconda-project==0.8.2
## appnope==0.1.0
## appscript==1.0.1
## argcomplete==1.9.4
## asn1crypto==0.24.0
## astroid==1.6.3
## astropy==3.0.2
## atomicwrites==1.2.1
## attrs==18.2.0
## awscli==1.16.31
...
```

Analysts working on the publication's code in future could look at the version numbers and ensure they download that version rather than the latest.

This approach is simple but isn't ideal. It:

* is tedious to do this by hand for each package
* isn't reproducible because the step between reading the version numbers and installing them isn't automated
* isn't _isolated_, meaning that you'll overwrite any current versions on your machine globally

What's better?

### Environments for dependency management

Ideally we want to _automate_ the process of recording packages and their version numbers and have them installed in an _isolated environment_ that's specific to our project. Doing this makes the project more _portable_ -- you could run it easily from another machine that's configured differently to your own -- and therfore more _reproducible_ by others.

#### Package managers in R

A popular choice in R is [the `packrat` package](https://rstudio.github.io/packrat/). When working in your project's repository, you can call `packrat::init()` to turn on 'Packrat mode' for your project. This means your package dependencies will now be stored in a _private package library_ that's isolated within the project folder. In this mode, any packages you install within your project are stored in the private library. Regular 'snapshots' are taken to record the state of dependencies.

A similar tool is [the `checkpoint` package](https://github.com/RevolutionAnalytics/checkpoint/wiki) from Microsoft's Revolution Analytics. It works like `packrat` but you simply `checkpoint()` your project for a given _date_. This allows you to call the packages from that date into a private library for that project. It works by fetching the packages from the Microsoft R Application Network (MRAN), which is a daily snapshot of [CRAN](https://cran.r-project.org/). One caveat is that you're dependent on MRAN to continue snapshotting CRAN and for it to continue to be maintained.

#### Virtual environments in Python

Setting up an isolated environment -- also called a virtual environment -- is also an option in Python with things like [`virtualenv` and `Pipenv`](https://docs.python-guide.org/dev/virtualenvs/).

We can set up a virtual environment in our project folder, install any modules we need and then record them in a file for people to use in future. A shell script to do this might be:

```{bash, eval=FALSE}
# 1. Navigate to your project folder
cd path/to/project/file

# 2. Create a virtual environment (a folder in your home directory)
virtualenv venv

# 3. 'Activate' the virtual environment
source venv/bin/activate

# 4. Install the modules you need
pip install <name>

# 5. Record the package-version list to a file in your home directory
pip freeze > requirements.txt

# 6. Deactivate the virtual environment when you're done
deactivate
```

When another user downloads your version-controlled project folder, the requirements.txt file will be there. Now they can create a virtual environment on their machine following steps 1 to 3 above, but rather than `pip install <module>` they can install based on the instructions from the requirements.txt file:

```{bash, eval=FALSE}
pip install -r requirements.txt
```

This will download the modules one by one into the virtual environment.

## Another problem

What about the version of the analytical software you're using? You may have written the original code in R version 3.4.1 but your computer is currently running R version 3.5.1. This is a similar problem to the issue of packages and modules: the functioning of code is also dependent on changes to the scripting tool itself.

You need to think bigger than an isolated environment for package installation. We need some kind of isolated environment for both the packages _and_ the tools. And why stop there? We could put our functions, tests and data in there too.

A 'container' for our publication is a good idea. We can isolate all the components of our RAP publication and make it even more portable.

### Docker

One way of doing this is to use Docker.

[^sessionInfo]: There's also a `session_info()` function in each of the `devtools`, `xfun` and `sessioninfo` packages, which provide more detail on things like a package's source (e.g. CRAN or GitHub) and give the version number in a separate column.
[^pip-pin]: These should be 'pinned' meaning that they're in the form `module==1.3.2` rather than `module>=1.3.2`. We're interested in storing _specific versions_, not _specific versions or newer_.